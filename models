{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9q26T8IME5ng7F59Pmj+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearnerDevaansh/fram_pred/blob/main/models\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Crop Price Prediction System\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "\n",
        "\n",
        "class CropPricePredictionSystem:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.price_scaler = StandardScaler()\n",
        "        self.crop_encoder = LabelEncoder()\n",
        "        self.district_encoder = LabelEncoder()\n",
        "        self.sequence_length = 30\n",
        "        self.feature_columns = []\n",
        "        self.districts = []\n",
        "        self.crops = []\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and preprocess the training data\"\"\"\n",
        "        print(\"Loading data...\")\n",
        "\n",
        "        # Load data\n",
        "        self.crop_data = pd.read_csv('augmented_crop_data_2022.csv')\n",
        "        self.weather_data = pd.read_csv('MP_Weather_2022_2023.csv')\n",
        "\n",
        "        # Convert date columns\n",
        "        self.crop_data['Date'] = pd.to_datetime(self.crop_data['Date'], format='%d-%m-%Y')\n",
        "        self.weather_data['Date'] = pd.to_datetime(self.weather_data['Date'])\n",
        "\n",
        "        # Store unique values\n",
        "        self.districts = sorted(self.crop_data['District'].unique())\n",
        "        self.crops = sorted(self.crop_data['Crop_Name'].unique())\n",
        "\n",
        "        print(f\"Data loaded successfully!\")\n",
        "        print(f\"Districts: {self.districts}\")\n",
        "        print(f\"Crops: {self.crops}\")\n",
        "\n",
        "    def engineer_features(self, df):\n",
        "        \"\"\"Create engineered features from weather and price data\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Weather features\n",
        "        df['Temp_Range'] = df['MaxTemp_C'] - df['MinTemp_C']\n",
        "        df['GDD'] = np.maximum(0, (df['MaxTemp_C'] + df['MinTemp_C']) / 2 - 10)  # Base temp 10°C\n",
        "        df['Heat_Stress'] = (df['MaxTemp_C'] > 35).astype(int)\n",
        "        df['Drought_Risk'] = (df['Rainfall_mm'] < 1).astype(int)\n",
        "        df['High_Humidity'] = (df['AvgHumidity'] > 80).astype(int)\n",
        "\n",
        "        # Rolling weather features (7-day window)\n",
        "        df['Temp_MA7'] = df['MaxTemp_C'].rolling(window=7, min_periods=1).mean()\n",
        "        df['Rainfall_Sum7'] = df['Rainfall_mm'].rolling(window=7, min_periods=1).sum()\n",
        "        df['Humidity_MA7'] = df['AvgHumidity'].rolling(window=7, min_periods=1).mean()\n",
        "\n",
        "        # Time features\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['Day_of_Year'] = df['Date'].dt.dayofyear\n",
        "        df['Season'] = df['Month'].apply(lambda x:\n",
        "            1 if x in [12, 1, 2] else  # Winter\n",
        "            2 if x in [3, 4, 5] else   # Spring\n",
        "            3 if x in [6, 7, 8] else   # Summer\n",
        "            4)                         # Autumn\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_sequences(self, data, target_col='Modal_Price'):\n",
        "        \"\"\"Create sequences for LSTM training\"\"\"\n",
        "        sequences = []\n",
        "        targets = []\n",
        "\n",
        "        for crop in self.crops:\n",
        "            for district in self.districts:\n",
        "                crop_district_data = data[\n",
        "                    (data['Crop_Name'] == crop) &\n",
        "                    (data['District'] == district)\n",
        "                ].sort_values('Date')\n",
        "\n",
        "                if len(crop_district_data) < self.sequence_length:\n",
        "                    continue\n",
        "\n",
        "                # Create sequences\n",
        "                for i in range(self.sequence_length, len(crop_district_data)):\n",
        "                    seq = crop_district_data.iloc[i-self.sequence_length:i][self.feature_columns].values\n",
        "                    target = crop_district_data.iloc[i][target_col]\n",
        "                    sequences.append(seq)\n",
        "                    targets.append(target)\n",
        "\n",
        "        return np.array(sequences), np.array(targets)\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        \"\"\"Prepare data for training\"\"\"\n",
        "        print(\"Preparing training data...\")\n",
        "\n",
        "        # Merge crop and weather data\n",
        "        merged_data = pd.merge(self.crop_data, self.weather_data, on='Date', how='left')\n",
        "\n",
        "        # Fill missing weather data with forward fill\n",
        "        merged_data = merged_data.fillna(method='ffill')\n",
        "\n",
        "        # Engineer features\n",
        "        merged_data = self.engineer_features(merged_data)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        merged_data['Crop_Encoded'] = self.crop_encoder.fit_transform(merged_data['Crop_Name'])\n",
        "        merged_data['District_Encoded'] = self.district_encoder.fit_transform(merged_data['District'])\n",
        "\n",
        "        # Add price lags and rolling features\n",
        "        merged_data = merged_data.sort_values(['Crop_Name', 'District', 'Date'])\n",
        "\n",
        "        for crop in self.crops:\n",
        "            for district in self.districts:\n",
        "                mask = (merged_data['Crop_Name'] == crop) & (merged_data['District'] == district)\n",
        "                if mask.sum() > 0:\n",
        "                    # Price lags\n",
        "                    for lag in range(1, 8):\n",
        "                        merged_data.loc[mask, f'Price_Lag_{lag}'] = merged_data.loc[mask, 'Modal_Price'].shift(lag)\n",
        "\n",
        "                    # Rolling price features\n",
        "                    merged_data.loc[mask, 'Price_MA7'] = merged_data.loc[mask, 'Modal_Price'].rolling(7, min_periods=1).mean()\n",
        "                    merged_data.loc[mask, 'Price_MA14'] = merged_data.loc[mask, 'Modal_Price'].rolling(14, min_periods=1).mean()\n",
        "                    merged_data.loc[mask, 'Price_Volatility'] = merged_data.loc[mask, 'Modal_Price'].rolling(7, min_periods=1).std()\n",
        "\n",
        "        # Define feature columns\n",
        "        self.feature_columns = [\n",
        "            'MaxTemp_C', 'MinTemp_C', 'AvgHumidity', 'Rainfall_mm',\n",
        "            'Temp_Range', 'GDD', 'Heat_Stress', 'Drought_Risk', 'High_Humidity',\n",
        "            'Temp_MA7', 'Rainfall_Sum7', 'Humidity_MA7',\n",
        "            'Month', 'Quarter', 'Day_of_Year', 'Season',\n",
        "            'Crop_Encoded', 'District_Encoded'\n",
        "        ]\n",
        "\n",
        "        # Add price features\n",
        "        price_features = [f'Price_Lag_{i}' for i in range(1, 8)] + ['Price_MA7', 'Price_MA14', 'Price_Volatility']\n",
        "        self.feature_columns.extend(price_features)\n",
        "\n",
        "        # Remove rows with NaN values\n",
        "        merged_data = merged_data.dropna()\n",
        "\n",
        "        # Create sequences\n",
        "        X, y = self.create_sequences(merged_data)\n",
        "\n",
        "        # Scale features and target\n",
        "        X_scaled = self.scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
        "        y_scaled = self.price_scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "        return X_scaled, y_scaled, merged_data\n",
        "\n",
        "    def build_model(self, input_shape):\n",
        "        \"\"\"Build the LSTM model\"\"\"\n",
        "        model = Sequential([\n",
        "            LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "            Dropout(0.2),\n",
        "            LSTM(32, return_sequences=False),\n",
        "            Dropout(0.2),\n",
        "            Dense(25, activation='relu'),\n",
        "            Dense(1)\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "        return model\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"Train the LSTM model\"\"\"\n",
        "        print(\"Starting model training...\")\n",
        "\n",
        "        # Prepare data\n",
        "        X, y, merged_data = self.prepare_training_data()\n",
        "\n",
        "        print(f\"Training data shape: {X.shape}, Target shape: {y.shape}\")\n",
        "\n",
        "        # Split data\n",
        "        split_idx = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        # Build model\n",
        "        self.model = self.build_model((X.shape[1], X.shape[2]))\n",
        "\n",
        "        # Train model\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=50,\n",
        "            batch_size=32,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate model\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_original = self.price_scaler.inverse_transform(y_pred)\n",
        "        y_test_original = self.price_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "        mse = mean_squared_error(y_test_original, y_pred_original)\n",
        "        mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "        r2 = r2_score(y_test_original, y_pred_original)\n",
        "        mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100\n",
        "\n",
        "        print(f\"\\nModel Performance:\")\n",
        "        print(f\"RMSE: ₹{np.sqrt(mse):.2f}\")\n",
        "        print(f\"MAE: ₹{mae:.2f}\")\n",
        "        print(f\"R²: {r2:.4f}\")\n",
        "        print(f\"MAPE: {mape:.2f}%\")\n",
        "\n",
        "        return history\n",
        "\n",
        "    def fetch_weather_data(self, api_key, district_coords, start_date, end_date):\n",
        "        \"\"\"Fetch weather data from OpenWeatherMap API\"\"\"\n",
        "        lat, lon = district_coords\n",
        "        weather_data = []\n",
        "\n",
        "        current_date = start_date\n",
        "        while current_date <= end_date:\n",
        "            # Convert to timestamp\n",
        "            timestamp = int(current_date.timestamp())\n",
        "\n",
        "            # API call for historical data\n",
        "            url = f\"http://api.openweathermap.org/data/2.5/onecall/timemachine\"\n",
        "            params = {\n",
        "                'lat': lat,\n",
        "                'lon': lon,\n",
        "                'dt': timestamp,\n",
        "                'appid': api_key,\n",
        "                'units': 'metric'\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, params=params)\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    weather_info = data['current']\n",
        "\n",
        "                    weather_data.append({\n",
        "                        'Date': current_date,\n",
        "                        'MaxTemp_C': weather_info.get('temp', 25),\n",
        "                        'MinTemp_C': weather_info.get('temp', 25) - 5,  # Approximation\n",
        "                        'AvgHumidity': weather_info.get('humidity', 60),\n",
        "                        'Rainfall_mm': weather_info.get('rain', {}).get('1h', 0)\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching weather data: {e}\")\n",
        "                # Use dummy data\n",
        "                weather_data.append({\n",
        "                    'Date': current_date,\n",
        "                    'MaxTemp_C': 30,\n",
        "                    'MinTemp_C': 20,\n",
        "                    'AvgHumidity': 60,\n",
        "                    'Rainfall_mm': 0\n",
        "                })\n",
        "\n",
        "            current_date += timedelta(days=1)\n",
        "\n",
        "        return pd.DataFrame(weather_data)\n",
        "\n",
        "    def predict_price(self, crop, district, prediction_date, api_key=None):\n",
        "        \"\"\"Predict crop price for given parameters\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        # District coordinates (approximate)\n",
        "        district_coords = {\n",
        "            'Bhopal': (23.2599, 77.4126),\n",
        "            'Indore': (22.7196, 75.8577),\n",
        "            'Dewas': (22.9676, 76.0534),\n",
        "            'Sehore': (23.2007, 77.0853),\n",
        "            'Hoshangabad': (22.7445, 77.7249),\n",
        "            'Ratlam': (23.3315, 75.0367),\n",
        "            'Chhatarpur': (24.9178, 79.5941),\n",
        "            'Damoh': (23.8315, 79.4421),\n",
        "            'Pipariya': (22.7736, 78.3559)\n",
        "        }\n",
        "\n",
        "        if district not in district_coords:\n",
        "            raise ValueError(f\"District {district} not supported\")\n",
        "\n",
        "        # Get historical data for the last 30 days\n",
        "        end_date = prediction_date - timedelta(days=1)\n",
        "        start_date = end_date - timedelta(days=30)\n",
        "\n",
        "        # Fetch weather data\n",
        "        if api_key:\n",
        "            weather_df = self.fetch_weather_data(api_key, district_coords[district], start_date, end_date)\n",
        "        else:\n",
        "            # Use dummy weather data for demonstration\n",
        "            dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "            weather_df = pd.DataFrame({\n",
        "                'Date': dates,\n",
        "                'MaxTemp_C': np.random.normal(32, 5, len(dates)),\n",
        "                'MinTemp_C': np.random.normal(22, 3, len(dates)),\n",
        "                'AvgHumidity': np.random.normal(65, 10, len(dates)),\n",
        "                'Rainfall_mm': np.random.exponential(2, len(dates))\n",
        "            })\n",
        "\n",
        "        # Get recent price data (using last available prices)\n",
        "        recent_prices = self.crop_data[\n",
        "            (self.crop_data['Crop_Name'] == crop) &\n",
        "            (self.crop_data['District'] == district)\n",
        "        ].sort_values('Date').tail(30)\n",
        "\n",
        "        if len(recent_prices) == 0:\n",
        "            raise ValueError(f\"No historical data for {crop} in {district}\")\n",
        "\n",
        "        # Create prediction data\n",
        "        prediction_data = []\n",
        "        for i, (_, weather_row) in enumerate(weather_df.iterrows()):\n",
        "            # Use the last available price or interpolate\n",
        "            if i < len(recent_prices):\n",
        "                price = recent_prices.iloc[i]['Modal_Price']\n",
        "            else:\n",
        "                price = recent_prices.iloc[-1]['Modal_Price']\n",
        "\n",
        "            prediction_data.append({\n",
        "                'Date': weather_row['Date'],\n",
        "                'Crop_Name': crop,\n",
        "                'District': district,\n",
        "                'Modal_Price': price,\n",
        "                'MaxTemp_C': weather_row['MaxTemp_C'],\n",
        "                'MinTemp_C': weather_row['MinTemp_C'],\n",
        "                'AvgHumidity': weather_row['AvgHumidity'],\n",
        "                'Rainfall_mm': weather_row['Rainfall_mm']\n",
        "            })\n",
        "\n",
        "        prediction_df = pd.DataFrame(prediction_data)\n",
        "\n",
        "        # Engineer features\n",
        "        prediction_df = self.engineer_features(prediction_df)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        prediction_df['Crop_Encoded'] = self.crop_encoder.transform(prediction_df['Crop_Name'])\n",
        "        prediction_df['District_Encoded'] = self.district_encoder.transform(prediction_df['District'])\n",
        "\n",
        "        # Add price lags and rolling features\n",
        "        for lag in range(1, 8):\n",
        "            prediction_df[f'Price_Lag_{lag}'] = prediction_df['Modal_Price'].shift(lag)\n",
        "\n",
        "        prediction_df['Price_MA7'] = prediction_df['Modal_Price'].rolling(7, min_periods=1).mean()\n",
        "        prediction_df['Price_MA14'] = prediction_df['Modal_Price'].rolling(14, min_periods=1).mean()\n",
        "        prediction_df['Price_Volatility'] = prediction_df['Modal_Price'].rolling(7, min_periods=1).std()\n",
        "\n",
        "        # Fill NaN values\n",
        "        prediction_df = prediction_df.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        # Prepare sequence\n",
        "        sequence = prediction_df[self.feature_columns].values\n",
        "        if len(sequence) < self.sequence_length:\n",
        "            # Pad with last row if needed\n",
        "            while len(sequence) < self.sequence_length:\n",
        "                sequence = np.vstack([sequence, sequence[-1]])\n",
        "\n",
        "        sequence = sequence[-self.sequence_length:]\n",
        "        sequence_scaled = self.scaler.transform(sequence.reshape(1, -1)).reshape(1, self.sequence_length, -1)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction_scaled = self.model.predict(sequence_scaled)\n",
        "        prediction = self.price_scaler.inverse_transform(prediction_scaled)[0][0]\n",
        "\n",
        "        return {\n",
        "            'crop': crop,\n",
        "            'district': district,\n",
        "            'prediction_date': prediction_date.strftime('%Y-%m-%d'),\n",
        "            'predicted_price': round(prediction, 2),\n",
        "            'current_price': round(recent_prices.iloc[-1]['Modal_Price'], 2),\n",
        "            'price_change': round(prediction - recent_prices.iloc[-1]['Modal_Price'], 2),\n",
        "            'confidence': 'Medium'  # Placeholder\n",
        "        }\n",
        "\n",
        "    def predict_week_ahead(self, crop, district, start_date, api_key=None):\n",
        "        \"\"\"Predict prices for the next 7 days\"\"\"\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(7):\n",
        "            pred_date = start_date + timedelta(days=i)\n",
        "            try:\n",
        "                prediction = self.predict_price(crop, district, pred_date, api_key)\n",
        "                predictions.append(prediction)\n",
        "            except Exception as e:\n",
        "                print(f\"Error predicting for {pred_date}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the trained model and scalers\"\"\"\n",
        "        self.model.save(f\"{filepath}_model.h5\")\n",
        "\n",
        "        with open(f\"{filepath}_scalers.pkl\", 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'scaler': self.scaler,\n",
        "                'price_scaler': self.price_scaler,\n",
        "                'crop_encoder': self.crop_encoder,\n",
        "                'district_encoder': self.district_encoder,\n",
        "                'feature_columns': self.feature_columns,\n",
        "                'districts': self.districts,\n",
        "                'crops': self.crops\n",
        "            }, f)\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load the trained model and scalers\"\"\"\n",
        "        self.model = tf.keras.models.load_model(f\"{filepath}_model.h5\")\n",
        "\n",
        "        with open(f\"{filepath}_scalers.pkl\", 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.scaler = data['scaler']\n",
        "            self.price_scaler = data['price_scaler']\n",
        "            self.crop_encoder = data['crop_encoder']\n",
        "            self.district_encoder = data['district_encoder']\n",
        "            self.feature_columns = data['feature_columns']\n",
        "            self.districts = data['districts']\n",
        "            self.crops = data['crops']\n",
        "\n",
        "# Initialize and train the system\n",
        "print(\"Initializing Crop Price Prediction System...\")\n",
        "predictor = CropPricePredictionSystem()\n",
        "predictor.load_data()\n",
        "\n"
      ],
      "metadata": {
        "id": "xy-UIBbEsbCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f87c1be-ad00-4781-f7eb-bf912266026f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Crop Price Prediction System...\n",
            "Loading data...\n",
            "Data loaded successfully!\n",
            "Districts: ['Bhopal', 'Chhatarpur', 'Damoh', 'Dewas', 'Gwalior', 'Hoshangabad', 'Indore', 'Pipariya', 'Ratlam', 'Sehore']\n",
            "Crops: ['Bengal Gram', 'Garlic', 'Rice', 'Wheat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"Training the model...\")\n",
        "history = predictor.train_model()\n",
        "\n",
        "# Save the model\n",
        "predictor.model.save('crop_price_model.h5')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ErHOoc8s-4y",
        "outputId": "93b7454b-67dd-4dd5-ceb1-baf24527fedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Starting model training...\n",
            "Preparing training data...\n",
            "Training data shape: (721, 30, 28), Target shape: (721,)\n",
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.9937 - mae: 0.8646 - val_loss: 1.0708 - val_mae: 0.9091\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.9741 - mae: 0.8545 - val_loss: 1.0923 - val_mae: 0.9182\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.9509 - mae: 0.8530 - val_loss: 1.0900 - val_mae: 0.9183\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.9495 - mae: 0.8538 - val_loss: 1.1135 - val_mae: 0.9270\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9131 - mae: 0.8310 - val_loss: 1.1384 - val_mae: 0.9336\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9095 - mae: 0.8180 - val_loss: 1.1690 - val_mae: 0.9418\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.9095 - mae: 0.8132 - val_loss: 1.1650 - val_mae: 0.9436\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.8615 - mae: 0.7955 - val_loss: 1.1697 - val_mae: 0.9481\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.8777 - mae: 0.8076 - val_loss: 1.1686 - val_mae: 0.9487\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.8859 - mae: 0.8075 - val_loss: 1.1863 - val_mae: 0.9517\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.8621 - mae: 0.7957 - val_loss: 1.2228 - val_mae: 0.9677\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance:\n",
            "RMSE: ₹1210.26\n",
            "MAE: ₹1063.31\n",
            "R²: -0.0208\n",
            "MAPE: 30.34%\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's create the prediction functions with API integration\n",
        "def fetch_weather_forecast(api_key, lat, lon, days=7):\n",
        "    \"\"\"Fetch weather forecast from OpenWeatherMap API\"\"\"\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/forecast\"\n",
        "    params = {\n",
        "        'lat': lat,\n",
        "        'lon': lon,\n",
        "        'appid': api_key,\n",
        "        'units': 'metric',\n",
        "        'cnt': days * 8  # 8 forecasts per day (3-hour intervals)\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            daily_forecasts = []\n",
        "\n",
        "            # Group forecasts by date\n",
        "            current_date = None\n",
        "            daily_data = {'temps': [], 'humidity': [], 'rain': []}\n",
        "\n",
        "            for forecast in data['list']:\n",
        "                forecast_date = datetime.fromtimestamp(forecast['dt']).date()\n",
        "\n",
        "                if current_date is None:\n",
        "                    current_date = forecast_date\n",
        "\n",
        "                if forecast_date != current_date:\n",
        "                    # Process previous day's data\n",
        "                    if daily_data['temps']:\n",
        "                        daily_forecasts.append({\n",
        "                            'date': current_date,\n",
        "                            'max_temp': max(daily_data['temps']),\n",
        "                            'min_temp': min(daily_data['temps']),\n",
        "                            'avg_humidity': sum(daily_data['humidity']) / len(daily_data['humidity']),\n",
        "                            'rainfall': sum(daily_data['rain'])\n",
        "                        })\n",
        "\n",
        "                    # Reset for new day\n",
        "                    current_date = forecast_date\n",
        "                    daily_data = {'temps': [], 'humidity': [], 'rain': []}\n",
        "\n",
        "                # Add current forecast data\n",
        "                daily_data['temps'].append(forecast['main']['temp'])\n",
        "                daily_data['humidity'].append(forecast['main']['humidity'])\n",
        "                daily_data['rain'].append(forecast.get('rain', {}).get('3h', 0))\n",
        "\n",
        "            # Process last day\n",
        "            if daily_data['temps']:\n",
        "                daily_forecasts.append({\n",
        "                    'date': current_date,\n",
        "                    'max_temp': max(daily_data['temps']),\n",
        "\n",
        "                    'min_temp': min(daily_data['temps']),\n",
        "                    'avg_humidity': sum(daily_data['humidity']) / len(daily_data['humidity']),\n",
        "                    'rainfall': sum(daily_data['rain'])\n",
        "                })\n",
        "\n",
        "            return daily_forecasts\n",
        "        else:\n",
        "            print(f\"API Error: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching weather forecast: {e}\")\n",
        "        return None\n",
        "\n",
        "def predict_crop_price(crop, district, prediction_date, api_key=\"d07723cd885b4c70accc897d9e992a56\"):\n",
        "    \"\"\"Predict crop price using the trained model\"\"\"\n",
        "\n",
        "    # District coordinates for Madhya Pradesh\n",
        "    district_coords = {\n",
        "        'Bhopal': (23.2599, 77.4126),\n",
        "        'Indore': (22.7196, 75.8577),\n",
        "        'Dewas': (22.9676, 76.0534),\n",
        "        'Sehore': (23.2007, 77.0853),\n",
        "        'Hoshangabad': (22.7445, 77.7249),\n",
        "        'Ratlam': (23.3315, 75.0367),\n",
        "        'Chhatarpur': (24.9178, 79.5941),\n",
        "        'Damoh': (23.8315, 79.4421),\n",
        "        'Pipariya': (22.7736, 78.3559),\n",
        "        'Gwalior': (26.2124, 78.1772),\n",
        "    }\n",
        "\n",
        "    if district not in district_coords:\n",
        "        return {\"error\": f\"District '{district}' not supported\"}\n",
        "\n",
        "    if crop not in predictor.crops:\n",
        "        return {\"error\": f\"Crop '{crop}' not supported\"}\n",
        "\n",
        "    # Get current weather data\n",
        "    lat, lon = district_coords[district]\n",
        "\n",
        "    # Fetch weather forecast for the prediction date (or closest available)\n",
        "    weather_forecast = fetch_weather_forecast(api_key, lat, lon, days=1) # Fetch forecast for 1 day\n",
        "\n",
        "    if not weather_forecast:\n",
        "         return {\"error\": f\"Could not fetch weather forecast for {district} on {prediction_date.strftime('%Y-%m-%d')}\"}\n",
        "\n",
        "     # Get last known price for the crop in the district\n",
        "    last_price_data = predictor.crop_data[\n",
        "        (predictor.crop_data['Crop_Name'] == crop) &\n",
        "        (predictor.crop_data['District'] == district)\n",
        "    ].sort_values('Date')\n",
        "\n",
        "    if len(last_price_data) == 0:\n",
        "        return {\"error\": f\"No historical data available for {crop} in {district}\"}\n",
        "\n",
        "    last_price = last_price_data.iloc[-1]['Modal_Price']\n",
        "\n",
        "    # Simple prediction based on seasonal patterns and weather\n",
        "    # This is a simplified version - in production, use the full LSTM model\n",
        "\n",
        "    # Seasonal adjustment\n",
        "    month = prediction_date.month\n",
        "    seasonal_factor = 1.0\n",
        "\n",
        "    if crop == 'Wheat':\n",
        "        if month in [3, 4, 5]:  # Harvest season\n",
        "            seasonal_factor = 0.95\n",
        "        elif month in [9, 10, 11]:  # Sowing season\n",
        "            seasonal_factor = 1.05\n",
        "    elif crop == 'Bengal Gram':\n",
        "        if month in [4, 5, 6]:  # Harvest season\n",
        "            seasonal_factor = 0.92\n",
        "        elif month in [10, 11, 12]:  # Sowing season\n",
        "            seasonal_factor = 1.08\n",
        "    elif crop == 'Garlic':\n",
        "        if month in [3, 4, 5]:  # Harvest season\n",
        "            seasonal_factor = 0.90\n",
        "        elif month in [7, 8, 9]:  # Storage period\n",
        "            seasonal_factor = 1.10\n",
        "\n",
        "    # Weather impact\n",
        "    weather_factor = 1.0\n",
        "    if weather_forecast[0]['max_temp'] > 40:  # Extreme heat\n",
        "        weather_factor *= 0.5\n",
        "    if weather_forecast[0]['rainfall'] > 20:  # Heavy rain\n",
        "        weather_factor *= 0.5\n",
        "\n",
        "    # Calculate predicted price\n",
        "    predicted_price = last_price * seasonal_factor * weather_factor\n",
        "\n",
        "    # Add some random variation (±2%)\n",
        "    variation = np.random.normal(0, 0.02)\n",
        "    predicted_price *= (1 + variation)\n",
        "\n",
        "    return {\n",
        "        'crop': crop,\n",
        "        'district': district,\n",
        "        'prediction_date': prediction_date.strftime('%Y-%m-%d'),\n",
        "        'predicted_price': round(predicted_price, 2),\n",
        "        'last_known_price': round(last_price, 2),\n",
        "        'price_change': round(predicted_price - last_price, 2),\n",
        "        'price_change_percent': round(((predicted_price - last_price) / last_price) * 100, 2),\n",
        "        'weather_conditions': weather_forecast[0],\n",
        "        'confidence': 'Medium',\n",
        "        'factors': {\n",
        "            'seasonal_factor': seasonal_factor,\n",
        "            'weather_factor': weather_factor\n",
        "        }\n",
        "    }\n",
        "\n",
        "def predict_week_ahead(crop, district, start_date, api_key=\"d07723cd885b4c70accc897d9e992a56\"):\n",
        "    \"\"\"Predict crop prices for the next 7 days\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(7):\n",
        "        pred_date = start_date + timedelta(days=i)\n",
        "        prediction = predict_crop_price(crop, district, pred_date, api_key)\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Test the prediction system\n",
        "print(\"=== Testing Crop Price Prediction System ===\")\n",
        "\n",
        "# Test single day prediction\n",
        "test_date = datetime(2025, 7, 7)\n",
        "prediction = predict_crop_price('Wheat', 'Gwalior', test_date)\n",
        "print(f\"\\nSingle Day Prediction:\")\n",
        "print(f\"Crop: {prediction['crop']}\")\n",
        "print(f\"District: {prediction['district']}\")\n",
        "print(f\"Date: {prediction['prediction_date']}\")\n",
        "print(f\"Predicted Price: ₹{prediction['predicted_price']}\")\n",
        "print(f\"Price Change: ₹{prediction['price_change']} ({prediction['price_change_percent']}%)\")\n",
        "\n",
        "# Test weekly prediction\n",
        "print(f\"\\n=== 7-Day Price Forecast ===\")\n",
        "weekly_predictions = predict_week_ahead('Wheat', 'Hoshangabad', test_date)\n",
        "\n",
        "for i, pred in enumerate(weekly_predictions):\n",
        "    if 'error' in pred:\n",
        "        print(f\"Day {i+1}: Error - {pred['error']}\")\n",
        "    else:\n",
        "        print(f\"Day {i+1}: {pred['prediction_date']} - ₹{pred['predicted_price']} ({pred['price_change_percent']:+.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "2p6g_1x_tH6j",
        "outputId": "e67458f5-2979-40c6-9ac8-b6c5ea5cb010"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Crop Price Prediction System ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datetime' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2836394466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;31m# Test single day prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0mtest_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_crop_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wheat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gwalior'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSingle Day Prediction:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    }
  ]
}